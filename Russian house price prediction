#Working on a larger dataset to practise on. Only had one hour to go over the data so, as you'll see the data is very much neglected, as I select
#5 out of 268 column to work on. The RSME is very bad, but the point of this exercise was to gain confidence of working with a dataset
#and no support whatsoever. I discovered two new strategies from Kaggle - 1) easily viewing all of the columns with their data, 
#2) visualising clearly the amount of Nan values for each column. Definitely progressing!

#As always, importing the relevant libraries, opening CSV and looking at data (see like 9 for the 1) referenced above.
import numpy as np
import pandas as pd
pd.set_option('display.max_columns',500)
import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline

df = pd.read_csv('Russian housing/train.csv')
df.head(5)
df.info()
df.describe

#Because I'm just doing a test run for practise I'm whittling the data down to just these columns:
columns = ['floor','build_year','kitch_sq','school_quota','metro_min_walk','shopping_centers_km']
final_data = df[columns]

#Visualising how many null values are in each column of the subset of data I've selected
missing_df = final_data.isnull().sum(axis=0).reset_index()
missing_df.columns = ['column_name', 'missing_count']
missing_df = missing_df.loc[missing_df['missing_count']>0]
ind = np.arange(missing_df.shape[0])
width = 0.9
fig, ax = plt.subplots(figsize=(12,5))
rects = ax.barh(ind, missing_df.missing_count.values, color='y')
ax.set_yticks(ind)
ax.set_yticklabels(missing_df.column_name.values, rotation='horizontal')
ax.set_xlabel("Count of missing values")
ax.set_title("Number of missing values in each column")
plt.show()

#Removing the two columns with a large amount of Nan values
final_data.drop('build_year',axis=1,inplace=True)
final_data.drop('kitch_sq',axis=1,inplace=True)
fd = final_data
fd.head(5)

#Filling in the Nan values with the mean of the respective column data
fd['school_quota'].fillna(value = fd['school_quota'].interpolate(),inplace=True)
fd['floor'].fillna(value = fd['school_quota'].interpolate(),inplace=True)
fd['metro_min_walk'].fillna(value = fd['school_quota'].interpolate(),inplace=True)
fd['shopping_centers_km'].fillna(value = fd['school_quota'].interpolate(),inplace=True)

#No more Nan data
fd.isnull

#Splitting data into train and test sets
from sklearn.model_selection import train_test_split
X = fd
y = df['price_doc']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

#Running linear regression (also ran random forest to similar effect
#I'm new to understanding the RSME but I've been told that the value below is very bad. So I'll revisit this code when I'm wiser and see what went wrong.
from sklearn import linear_model
clf = linear_model.LinearRegression()
clf.fit(X_train,y_train)
prediction = clf.predict(X_test)
from sklearn import metrics
print(np.sqrt(metrics.mean_squared_error(y_test, prediction)))
4505361.66682

plt.scatter(y=prediction,x=y_test)






