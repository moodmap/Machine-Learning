#I created this with help from the online course 'Data science and machine learning bootcamp'
#The program takes into account a given film and its rating and finds correlations where the same users have rated other movies.

import numpy as np
import pandas as pd

#Bringing in the data - one regarding user rating, one containing the names of the movies
column_names = ['user_id','item_id','rating','timestamp']
df = pd.read_csv('u.data',sep='\t',names=column_names)
df.head()

movie_titles = pd.read_csv('Movie_Id_Titles')
movie_title.head()

#Merging the two sets of data into a single dataframe, keeping only one item_id column between the two
df = pd.merge(df,movie_titles,on='item_id')
df.head()

import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('white')
%matplotlib inline

#Visualising the data in more detail
#Looking at the highest rated movies and which movies have been rated the most
df.groupby('title')['rating'].mean().sort_values(ascending=False).head()
df.groupby('title')['rating'].count().sort_values(ascending=False).head()

#Creating a new dataframe containing film titles and the mean rating for each, then adding a third column showing how many ratings were made for the movie
ratings = pd.DataFrame(df.groupby('title')['rating].mean())
ratings.head()
ratings['num of ratings'] = pd.DataFrame(df.groupby('title')['ratings'].count())
ratings.head()


plt.figure(figsize=(10,4))
ratings['num of ratings].hist(bins=70)

plt.figure(figsize=(10,4))
ratings['rating'].hist(bins=70)
sns.jointplot(x='rating',y='num of ratings',data=ratings,alpha=0.5)

#Using pivot table to create a matrix of the relevant columns
moviemat = df.pivot_table(index='user_id',columns='title',,value='rating')
moviemat.head()

#Looking at the most rated movies
ratings.sort_values('num of ratings', ascending=False).head(10)
ratings.head()

#Creating variables for comparing two of the most ratedmovies
starwars_user_ratings = moviemat['Star Wars (1977)']
liarliar_user_ratings = moviemat['Liar Liar (1997)']
starwars_user_ratings.head()

#Seeing which movies are most correlated with star wars and liar liar based on ratings
similar_to_starwars = moviemat.corrwith(starwars_user_ratings)
similar_to_liarliar = moviemat.corrwith(liarliar_user_ratings)

#Creating a cdataframe that show all the movies and how correlated they are with star wars (1 being the most correlated)
corr_starwars = pd.DataFrame(similar_to_starwars,columns = ['Correlation'])
corr_starwars.dropna(inplace=True)
corr_starwars.head()

#Sorting data so that the most correlated now appear at the top
corr_starwars.sort_values('Correlation',ascending=False).head(10)

#Adding in the number of ratings as well
#Taking a look at how many ratings the most correlated films received. It turns out that there are a lot of obscure films
#that received the same rating but only a few times.
corr_starwars = corr_starwars.join(ratings['num of ratings'])
corr_starwars.head()


#So I'm going to filter those out and have only films appear that have been rated over 100 times
corr_starwars[corr_starwars['num of ratings']>100].sort_values('Correlation',ascending=False).head()

#Exploring liar liar by creating a dataframe containing movie titles and correlation scores
corr_liarliar = pd.DataFrame(similar_to_liarliar,columns = ['Correlation'])

#There are a lot of Nan's. These are useless to us so removing from the dataframe.
corr_liarliar.dropna(inplace=True)

#Adding in the number of ratings
corr_liarliar = corr_liarliar.join(ratings['num of ratings'])

#Filtering out films that have been rated less than 100 times.
corr_liarliar[corr_liarliar['num of ratings']>100].sort_values('Correlation',ascending=False).head()
